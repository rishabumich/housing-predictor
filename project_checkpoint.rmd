---
title: 'Stats 401: Project Checkpoint'
author: "Rishab Gupta"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_collapsed: true
    theme: lumen
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Project Checkpoint

This assignment is designed for you to begin your data exploration process. Before creating a multiple linear regression model, you should always familiarize yourself with the data set and its individual variables. In this checkpoint, you will create numerical summaries and visualizations that will help guide decisions you make during your modeling process...such as:

- which predictors are helpful in explaining the response
- which variables need a transformation
- which variables could benefit from an interaction
- etc.

Most of your data sets have several predictors to choose from. For the project checkpoint, I only ask that you analyze a few of them. This will give you a baseline model called your "Initial Model". After the checkpoint, your goal will be to try and improve upon this initial model. Remove unhelpful predictors, add helpful predictors, include transformations and interactions, etc. in order to create the best possible model for your final report. Remember, creating a regression model is an *iterative process*!  

One last note is that your final model does not need to contain the variables from your project proposal (or your initial model). Explore your data and have some fun! 

If you have any questions throughout the process, please ask us - the instructional team is here to help!


***


### Creating an RStudio Project

Now is a great time to create a dedicated RStudio Project (like you did in Lab 6) for all of your project documents. To do this, please follow these steps:

1. Open up a *new* session of RStudio
2. Navigate to File > New Project
3. Click on New Directory
4. Click on New Project
5. Give your project a "Directory name" (something like "stats401project")
6. Decide where you would like the project stored (I keep mine - and all other Stats 401 assignments - in a folder on my computer called stats401)
7. Click "Create Project" 
8. Move this "project_checkpoint.Rmd" document to the project folder
9. Move your data set to the project folder 

If you are working on a team, I recommend that one student handles most of the coding - so that you don't need to keep sending your zipped project folder back and forth. You are also welcome to use [Posit.Cloud](https://posit.cloud/learn/guide) and share a space between multiple users. If you want more information, let me know! 


***


### Load Packages

First load in any necessary packages that you need.

```{r load_packages}
library(ggplot2)
```


***


### Read and Preview Data (2 points)

Once you have created your RStudio Project and moved your data set into the project folder, you will then be able to read in your data. Use the `read.csv()` function and store it for use throughout the file.

Reach out to us if you need help reading in your data! 

```{r read_data}
housing <- read.csv("kc_housing.csv")

```

Use the `head()` function to provide your reader with a preview of the data set. 

```{r preview_data}
head(housing)

```

Please do not print/output your *entire* data set. This will result in a deduction of points.

Once you have successfully loaded your data, complete the tasks below to complete the project checkpoint. Failure to properly follow the instructions will result in point deductions.


***


### Variables (2 points)

Fill in the following bullet points with the variables you will be analyzing below. I recommend starting with the variables you described in your project proposal. These variables can change throughout your modeling process. 

- **Response:** House Price
- **Quantitative Predictor #1:** Living Size
- **Quantitative Predictor #2:** Lot Size
- **Quantitative Predictor #3:** Number of Bedrooms
- **Categorical Predictor:** Waterfront

While your final model (that you create later on) is welcome to contain any number of predictors, please only analyze the variables listed above in the checkpoint below. 


***


### Numerical Summaries (3 points)

Calculate the following numerical summaries:

- Using the `summary()` function, compute numerical summaries for your response 
- Using the `sd()` function, compute the standard deviation for your response
- Using the `summary()` function, compute numerical summaries for your three quantitative predictors
- Using the `table()` function, create a frequency table for your categorical predictor

```{r summary_response}
summary(housing$price)

```

```{r standard_deviation_response}
sd(housing$price)

```

```{r summary_predictor1}
summary(housing$living)

```

```{r summary_predictor2}
summary(housing$lot)

```

```{r summary_predictor3}
summary(housing$bedrooms)

```

```{r table_categorical_predictor}
table(housing$waterfront)

```


***


### Histograms (10 points)

Using `ggplot()`, create a histogram for each of your four quantitative variables (one for the response and one for each of the three predictors). *Be sure to give each plot appropriate axis labels and a title.* 

```{r histogram_response}
ggplot(housing, aes(x = price)) +
  geom_histogram(binwidth = 50000) +
  labs(title = "Histogram of House Prices", x = "House Price", y = "Frequency") +
  theme_minimal()

```

```{r histogram_predictor1}
ggplot(housing, aes(x = living)) +
  geom_histogram(binwidth = 100) +
  labs(title = "Histogram of Living Size", x = "Living Size (sqft)", y = "Frequency") +
  theme_minimal()

```

```{r histogram_predictor2}
ggplot(housing, aes(x = lot)) +
  geom_histogram(binwidth = 500) +
  labs(title = "Histogram of Lot Size", x = "Lot Size (sqft)", y = "Frequency") +
  theme_minimal()

```

```{r histogram_predictor3}
ggplot(housing, aes(x = bedrooms)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Histogram of Number of Bedrooms", x = "Number of Bedrooms", y = "Frequency") +
  theme_minimal()

```

Reflect on your histograms by answering the question below. 

Do any of the distributions exhibit a heavy right skew? Thinking ahead: if so, a log transformation might be helpful.  

**Answer:** I'm seeing a ver yheavy right skew on the histograms for house price, living size, and lot size. I noticed in these historgrams, especially for the histogram of lot size, that there are a few very high values which are throwing all the data off and making it look like a heavy right skew in the graph. Maybe these values could be removed in my final analysis? For now though I know that these threwe variables will need some sort of manipulation or log transformation.


***


### Scatterplot Matrix (8 points)

Create a **scatterplot matrix** that includes your response variable and the three quantitative predictors. Note: we are not asking for individual scatterplots - this will result in a deduction of points.

```{r scatterplot_matrix}
variables <- housing[c("price", "living", "lot", "bedrooms")]

# Creating the scatterplot matrix
pairs(variables, 
      main = "Scatterplot Matrix", 
      pch = 1,
      cex=0.75
      )

```

Reflect on your scatterplot matrix by answering the questions below. 

Which predictor(s) appear to exhibit stronger relationships with the response?

**Answer:** Visually, it looks like the living size has the strongest linear relationship with the response variable, price. I am concerened though about why the lot variable is all grouped up on the edge. It looks like in the massive cluster of lot sizes, the price is different for every single one. This could mean that the lot size doesn't impact the price but that sounds counterintuitive.


Do any of the predictors appear to have a curved (non-linear) relationship with the response? Thinking ahead: if so, a quadratic fit might be helpful!  

**Answer:** It doesn't look like any of the predictors have a non-linear relatiobship with the response, but in the project if I do choose different predictors we might see this behavior. 


Does any *predictor* appear to have a strong linear relationship with *another predictor*? Thinking ahead: if so, this could be a sign of multicollinearity. (This topic will be covered in a later lecture.) 

**Answer:** I am not seeing any big signs of multicollinearity however when we run the cor function on the data, we can numerically see the strength between variables rather than relying on a visual representation of it. 


Important Note: if you decide to include a log transformation for any of your variables, then you should re-plot your scatterplot matrix with the transformed variable(s). This does not have to be done in the checkpoint, but should be included in your final analysis!


***


### Scatterplot with Color (5 points)

Select one of your three quantitative predictors from above (perhaps the predictor that appears to have the strongest relationship with the response) and plot it against the response using `ggplot()`. Use your categorical variable to plot by color. *Be sure to give your plot appropriate axis labels and a title.* 

Reminder: you may need to convert your categorical variable to a factor! 

```{r scatterplot_with_color}

housing$waterfront <- factor(housing$waterfront, levels = c("no", "yes"))
housing$color <- ifelse(housing$waterfront == "yes", "Red", "Blue")

ggplot(housing, aes(x = living, y = price, color = color)) +
  geom_point() +
  labs(x = "Living Area Size", y = "Housing Price", title = "Living Area Size vs. Housing Price by Waterfront Presence") +
  theme_minimal() +
  scale_color_identity()

```

Reflect on your scatterplot by answering the question below. 

Does the relationship between X and Y appear to differ by group? Do these relationships appears to have different slopes? Thinking ahead: if so, an interaction might be helpful!  

Note: it may be hard to conclude anything from this plot, by try to give it your best shot! (It might just look like a completely random scatter of colors.)

**Answer:** I'm seeing a lot of the data clustering towards the left side of the scatterplot but overall I'm seeing a pretty similar slope for both groups of data. It looks like the properties with waterfronts generally have slightly higher prices especially the ones on the right side of the plot with those high prices. I'm not sure right now if I will need an interaction in my final plot but maybe that could be useful later depending on the final predictors I do use.


***


### Initial Model (8 points)

Create and store a linear model using all four predictor variables (the three quantitative predictors *and* the categorical predictor. Do **not** include any transformations, quadratic fits, or interactions (regardless of your answers above). Pass your stored model through the `summary()` function.

```{r intitial_model_summary}
initial_model <- lm(price ~ living + lot + bedrooms + waterfront, data = housing)
summary(initial_model)

```

Report the RMSE value and R^2 value. 

**RMSE:** The RMSE value is 399,200

**R^2:** The R^2 value is 0.771


For your model, create the two diagnostic plots we have discussed in lecture. 

```{r diagnostic_plot1}
# Residual Plot

plot(fitted(initial_model), resid(initial_model),
     xlab = "Fitted Values",
     ylab = "Residuals",
     main = "Residual Plot")

# Add a horizontal line at 0 to show the ideal residual value
abline(h = 0, col = "red")

```

```{r diagnostic_plot2}
# QQ Plot
qqnorm(resid(initial_model),
       main = "QQ Plot of Residuals",
       xlab = "Theoretical Quantiles",
       ylab = "Sample Quantiles")
qqline(resid(initial_model), col = "red")

```

Is this assumption of linearity reasonably met?

**Answer:** In the residual plot, it looks like the values are pretty randomly scattered around the horizontal line so I feel the assumption of linearity is somewhat met based on this.


Is this assumption of constant variance reasonably met?

**Answer:** In the residual plot, the values are not super evenly spread around the graph making me question if the assumption of constant variance is met. To be more confident, I would have liked the values to be a little less grouped, especially the one's on the left side.


Is this assumption of normality reasonably met?

**Answer:**  Based on the QQ plot, the big bulk of values is conforming to the line however there is some variations around the edges. Overall though, I think the assumption of normality is met. 


Taking into account everything you have learned about your data, your goal moving forward will be to improve upon this initial model!


***


### Conclusions (2 points)

Reflect on your analysis above (in 2 - 4 sentences). Highlight any key findings from your initial data exploration. Where do you plan to go from here? I am not looking for anything in particular in this section, just a general summary of your findings! 

**Answer:** Overall, I think I chose some solid predictors for my response variable of price. I want to tweak this though and perform the same steps as above for more variables to find the best predictors to use. Right now, I am concerned about my scatterplot matrix and some of the shapes of the variables there. I felt a lot of the plots just had a lot of values scrunched together on the left rather than showing any strong relationships with the response. Other than living size I am not super confident with the other quantiative predictors. I definitely need to do some log transformations on the data to make it more usable. I also feel like the assumption of constant variance for the living size can't be super confidently said right now. Even though this was the variable I was the most confident in, I still am not super confident in that specific assumption and I know that these asusmptions will not be met for the other variables.


If you have any questions for the instructional team (about coding, the direction of your analysis, possible transformations, etc.), please reach out via email or on Piazza! After the exam, you will be able to book an appointment to discuss project-related questions with Mark. More information will be posted to Canvas.  


